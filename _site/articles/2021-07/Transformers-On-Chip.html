<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="description" content="This is departure from my usual tech blog. In the current series titled Artificial-Intelligence-based-chip-design, I/we present the use of Artificial Intelli...">
  <meta name="keywords" content="blog and jekyll">
  <meta name="author" content="Artificial Intelligence based chip design: Transformers on Chip | Slowbreathing">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#f5f5f5">

  <!-- Twitter Tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Artificial Intelligence based chip design: Transformers on Chip | Slowbreathing">
  <meta name="twitter:description" content="This is departure from my usual tech blog. In the current series titled Artificial-Intelligence-based-chip-design, I/we present the use of Artificial Intelli...">
  
    <meta property="twitter:image" content="http://localhost:4000/img/chipdesign/transformersonchip.png">
  

  <!-- Open Graph Tags -->
  <meta property="og:type" content="blog">
  <meta property="og:url" content="http://localhost:4000/articles/2021-07/Transformers-On-Chip">
  <meta property="og:title" content="Artificial Intelligence based chip design: Transformers on Chip | Slowbreathing">
  <meta property="og:description" content="This is departure from my usual tech blog. In the current series titled Artificial-Intelligence-based-chip-design, I/we present the use of Artificial Intelli...">
  
    <meta property="og:image" content="http://localhost:4000/img/chipdesign/transformersonchip.png">
  
  <title>Artificial Intelligence based chip design: Transformers on Chip | Slowbreathing</title>

  <!-- CSS files -->
  <link rel="stylesheet" href="http://localhost:4000/css/font-awesome.min.css">
  <link rel="stylesheet" href="http://localhost:4000/css/main.css">

  <link rel="canonical" href="http://localhost:4000/articles/2021-07/Transformers-On-Chip">
  <link rel="alternate" type="application/rss+xml" title="Slowbreathing" href="http://localhost:4000/feed.xml" />

  <!-- Icons -->
  <!-- 16x16 -->
  <link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
  <!-- 32x32 -->
  <link rel="shortcut icon" href="http://localhost:4000/favicon.png">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!--<script async src="https://www.googletagmanager.com/gtag/js?id=UA-142206738-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-142206738-1');
  </script>-->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Slowbreathing" />
</head>


<body>
  <div class="row">
    <div class="col s12 m3">
      <div class="table cover">
        

<div class="cover-card table-cell table-middle">
  
  <a href="http://localhost:4000/">
    <img src="http://localhost:4000/img/leonids-logo.png" alt="" class="avatar">
  </a>
  
  <a href="http://localhost:4000/" class="author_name">Mohit Kumar</a>
  <span class="author_job">Researcher/Consultant/Trainer</span>
  <span class="author_bio mbm">Programming is more than just typing.</span>
  <nav class="nav">
    <ul class="nav-list">
      <li class="nav-item">
        <a href="http://localhost:4000/">home</a>
      </li>
       
      <li class="nav-item">
        <a href="http://localhost:4000/archive/">Archive</a>
      </li>
          
      <li class="nav-item">
        <a href="http://localhost:4000/categories/">Categories</a>
      </li>
            
      <li class="nav-item">
        <a href="http://localhost:4000/resume/">about me</a>
      </li>
        
      <li class="nav-item">
        <a href="http://localhost:4000/tags/">Tags</a>
      </li>
                 
    </ul>
  </nav>
  <script type="text/javascript">
  // based on https://stackoverflow.com/a/10300743/280842
  function gen_mail_to_link(hs, subject) {
    var lhs,rhs;
    var p = hs.split('@');
    lhs = p[0];
    rhs = p[1];
    document.write("<a class=\"social-link-item\" target=\"_blank\" href=\"mailto");
    document.write(":" + lhs + "@");
    document.write(rhs + "?subject=" + subject + "\"><i class=\"fa fa-fw fa-envelope\"></i><\/a>");
  }
</script>
<div class="social-links">
  <ul>
    
      <li>
      <script>gen_mail_to_link('mohit.riverstone@gmail.com', 'Hello from website');</script>
      </li>
    
    <li><a href="https://twitter.com/stillwaters_ia" class="social-link-item" target="_blank"><i class="fa fa-fw fa-twitter"></i></a></li>
    <li><a href="https://facebook.com/mohit.kumar.965" class="social-link-item" target="_blank"><i class="fa fa-fw fa-facebook"></i></a></li>
    
    <li><a href="https://linkedin.com/in/mohit-kumar-05621b62" class="social-link-item" target="_blank"><i class="fa fa-fw fa-linkedin"></i></a></li>
    
    
    <li><a href="https://instagram.com/slowbreathing.github.io" class="social-link-item" target="_blank"><i class="fa fa-fw fa-instagram"></i></a></li>
    
    <li><a href="https://github.com/Slowbreathing" class="social-link-item" target="_blank"><i class="fa fa-fw fa-github"></i></a></li>
    
    
    
    
    <li><a href="https://www.pinterest.com/mohitkumar965" class="social-link-item" target="_blank"><i class="fa fa-fw fa-pinterest"></i></a></li>
    
    
    
    
    
    
    
    
    
    
  </ul>
</div>

</div>

      </div>
    </div>
    <div class="col s12 m9">
      <div class="post-listing">
        <a class="btn" href= "http://localhost:4000/" >
  Home
</a>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://vincenttam.github.io/javascripts/MathJaxLocal.js"
>
</script>



<div class="post-image-feature">
  <img class="feature-image" src=
  
  "http://localhost:4000/img/chipdesign/transformersonchip.png"
  
  alt="Artificial Intelligence based chip design: Transformers on Chip feature image">

  
</div><!-- /.image-wrap -->



<div id="post">
  <header class="post-header">
    <h1 title="Artificial Intelligence based chip design: Transformers on Chip">Artificial Intelligence based chip design: Transformers on Chip</h1>
    <span class="post-meta">
      <span class="post-date">
        3 JUL 2021
      </span>
      •
      <span class="read-time" title="Estimated read time">
  
  
    10 mins read
  
</span>

    </span>

  </header>

  <article class="post-content">
    <h3 id="artificial-intelligence-based-chip-design"><a href="/tags/#Artificial-Intelligence-based-chip-design">Artificial Intelligence based chip design</a></h3>
<ol>
  <li><a href="Transformers On Chip">Artificial Intelligence based chip design: Transformers on Chip</a> <strong>(<a href="Transformers On Chip">part-1</a>)</strong>
    <ul>
      <li><a href="Transformers-On-Chip#Introduction">Introduction</a></li>
      <li><a href="Transformers-On-Chip#STT(Speech-to-Text)">STT(Speech-to-Text)</a></li>
      <li><a href="Transformers-On-Chip#TTS(Text-to-Speech)">TTS(Text-to-Speech)</a></li>
      <li><a href="Transformers-On-Chip#FPGAs as modern digital ShapeShifters">FPGAs as modern digital ShapeShifters</a></li>
      <li><a href="Transformers-On-Chip#Optimizing on Hardware Accelerator">Optimizing on Hardware Accelerator</a></li>
      <li><a href="Transformers-On-Chip#Optimizing on Hardware Accelerator(MAC Style)">Optimizing on Hardware Accelerator(MAC Style)</a></li>
      <li><a href="Optimizing on Hardware Accelerator(Systolic Array Style)">Optimizing on Hardware Accelerator(Systolic Array Style)</a></li>
      <li><a href="Transformers-On-Chip#Variables in the design">Variables in the design</a></li>
      <li><a href="Transformers-On-Chip#Summary1">Summary</a></li>
    </ul>
  </li>
  <li><a href="ChipDesign">Artificial Intelligence based chip design: Chip Design</a> <strong>(<a href="ChipDesign">part-2</a>)<strong>
</strong></strong>    <ul>
      <li><a href="ChipDesign#Introduction">Introduction</a></li>
      <li><a href="ChipDesign#Chip Design: Layout, Locality and Resource Allocation">Chip Design: Layout, Locality and Resource Allocation</a></li>
      <li><a href="ChipDesign#Deep Reinforcement Learning Agent">Deep Reinforcement Learning Agent</a></li>
      <li><a href="ChipDesign#Our Rules of the Game">Our Rules of the Game</a></li>
      <li><a href="ChipDesign#Summary2">Summary</a></li>
      <li><a href="ChipDesign#Future">Future</a></li>
    </ul>
  </li>
</ol>

<h1><a name="Introduction"></a></h1>
<h3 id="introduction">Introduction</h3>
<p>We have taken a traditional <strong>(TTS)Text-to-speech</strong> and <strong>(STT)Speech-to-text</strong> system and spun it on an <strong>FPGA microchip</strong>. In the pipeline of a traditional TTS system, there is a Seq-to-Seq LSTM layer rearing its “ugly latency head”. It takes approximately <strong>tens of thousands</strong> of iterations of this network to generate a second of audio.Sometimes this latency is not acceptable. Sometimes, this latency is not acceptable. Latency of these systems can be majorly attributed to the LSTMs, the technology of the day. LSTMs still have their uses, but for speech-based latency sensitive systems, they have limitations. LSTMs have played their part in the Deep Learning history and it is time for them to pass on the baton to the new King, The <a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">Transformers</a>.</p>

<h1 id="-1"><a name="STT(Speech-to-Text)"></a></h1>
<h4 id="sttspeech-to-text">STT(Speech-to-Text)</h4>
<p>Firstly, we took the STT based on <strong><a href="https://arxiv.org/abs/2005.08100">Conformer</a></strong> (a <strong><a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">transformer</a></strong> variant) and rewrote it using Trax.<br />
Why Trax? Well, it has an optimizing <strong>Just-In-Time compiler</strong> for Machine learning. We have <strong>extended that for FPGA</strong>. But more on that later.</p>

<p>It was a huge improvement on the LSTM variant. While there was a marked improvement, it wasn’t enough. And this was running on a 2020 GPU.</p>

<p>Transformers are essentially <strong>(<a href="https://paperswithcode.com/method/multi-head-attention">(MHSA)Multi-headed-Self-Attention</a>)</strong> and a <strong>(FFM)feed forward Module<strong>. Both these are matrix multiplications of grand and varying scale. The Conformer has an additional CM(Convolutional Module) which is a matrix filter operation.</strong></strong></p>

<figure>
    
    <img src="/img/chipdesign/speechtotext.png" alt="Image: figure-1: &lt;strong&gt;For most part this is a regular transfomer with a convolution in between&lt;/strong&gt;" hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-1: <strong>For most part this is a regular transfomer with a convolution in between</strong></span></center></figcaption>
</figure>

<h1 id="-2"><a name="TTS(Text-to-Speech)"></a></h1>
<h4 id="ttstext-to-speech">TTS(Text-to-Speech)</h4>

<p>Secondly, we took the TTS based on the transformer and did exactly the same. Again it was a decent improvement on the LSTM version. But, not enough. Again, this was running on a 2020 GPU.</p>

<figure>
    
    <img src="/img/chipdesign/texttospeech.png" alt="Image: figure-2: &lt;strong&gt;This is a regular transformer with speech fed into the decoder, similar to NMT decoder&lt;/strong&gt;" hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-2: <strong>This is a regular transformer with speech fed into the decoder, similar to NMT decoder</strong></span></center></figcaption>
</figure>

<p>GPUs are great at handling the “grand” part despite some transformers having billions to even trillions of parameters.</p>

<blockquote>
  <ul>
    <li>The “varying” part is proving extremely tricky for GPUs. Both MHSA and FFM have varying parallelism requirements(from one model to another).</li>
    <li>Also, the standard precision leads to lots of wastage energy. GPU’s SIMD/SIMT lock-step style execution model makes matters worse. Lock step style execution is prohibitive in terms of energy wastage.</li>
    <li>Last but not least, the extra control structure on the GPU is not useful(wasteful) for matrix multiplication.
GPU is a general-purpose device and for something as specific as tuning a massive matrix multiplication it is found wanting. It is not a natural fit would be the right phrase.</li>
    <li>All of the above contribute to tons of electricity, produce a lot of heat, and use fans for cooling.
      <ul>
        <li>And a large number of environments where we apply deep learning like speech devices, self-driving cars, production lines, etc, are not agreeable to it.</li>
        <li>This also makes the maintenance and life expectancy of a GPU an issue.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h1 id="-3"><a name="FPGAs as modern digital ShapeShifters"></a></h1>
<h4 id="fpgas-as-modern-digital-shapeshifters">FPGAs as modern digital ShapeShifters</h4>

<p>The CPUs and especially GPUs are nearing their transistor limit.
The world is moving toward specialized hardware to meet the exponentially growing demand for computers:</p>

<figure>
    
    <img src="/img/chipdesign/fpga.png" alt="Image: figure-3: &lt;strong&gt;FPGA fabric. While there are differences from one manufacturer to the next, The resources are similar.&lt;/strong&gt;" hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-3: <strong>FPGA fabric. While there are differences from one manufacturer to the next, The resources are similar.</strong></span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Field-programmable gate arrays (FPGAs) are reconfigurable computer chips that can be programmed to implement any digital hardware circuit.</li>
    <li>FPGAs consist of an array of different types of programmable blocks (logic, IO, and others) that can be flexibly interconnected using prefabricated routing tracks with programmable switches between them.</li>
    <li>The bit-level reconfigurability of FPGAs enables implementation of the exact hardware needed for each application (e.g. datapath bit-width, pipeline stages, number of parallel compute units, memory subsystem, etc.) instead of the fixed one-size-fits-all architecture of CPUs or GPUs.</li>
    <li>Consequently, they can achieve higher efficiency than CPUs or GPUs by implementing instruction-free streaming hardware</li>
    <li><strong>FPGA-RAM</strong>
      <ul>
        <li>An FPGA BRAM(BlockRAM) consists of an SRAM-based memory core, with additional peripheral circuitry to make them more configurable for multiple purposes and to connect them to the programmable routing FPGA vendors can add circuitry that allows designers to repurpose the LUTs(Look Up Tables) that form the logic fabric into additional RAM blocks.</li>
      </ul>
    </li>
    <li><strong>DSP Blocks</strong>
      <ul>
        <li>With the prevalence of multipliers in FPGA designs from key application domains, and their lower area/delay/power efficiency when implemented in soft logic, they quickly became a candidate for hardening as dedicated circuits in FPGA architectures.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h1 id="-4"><a name="Optimizing on Hardware Accelerator"></a></h1>
<h4 id="optimizing-on-hardware-accelerator">Optimizing on Hardware Accelerator</h4>
<p>The idea here is to hardware accelerate the huge matrix multiplication which is the core of Transformers. Given the size of the matrices in transformers ( a few billion parameters in 2020), there is practically no chance of them fitting inside a top end FPGA board, not for at least the next decade.
So the trick is to chop these huge matrices being multiplied into smaller tiles and reuse these tiles as much as possible before moving on to the next tile. One of the oldest tricks in a new Avatar.</p>

<p><strong>There are 4 key points of FPGA Hardware Optimization</strong></p>
<blockquote>
  <ul>
    <li><strong>Play to FPGAs strength, no extra control logic</strong></li>
    <li><strong>Minimize access to OFF-chip RAM by having multi level on chip buffer made of BRAM and LUTRAM</strong></li>
    <li><strong>Maximize the compute parallelism (PE)ProcessingElements</strong></li>
    <li><strong>And the most vital, balance the above 2.</strong>
      <ul>
        <li><strong>PEs must be well fed and not starving</strong></li>
        <li><strong>Balance cached data with streaming( weights(Mul1) may be cached more and the input will be streamed more(Mul2))</strong></li>
      </ul>
    </li>
  </ul>
</blockquote>

<h1 id="-5"><a name="Optimizing on Hardware Accelerator(MAC Style)"></a></h1>
<h4 id="optimizing-on-hardware-acceleratormac-style">Optimizing on Hardware Accelerator(MAC Style)</h4>

<p>The <strong>hardware <span style="color:#1950b6">ma</span><span style="color:#83f3f2">pp</span><span style="color:#f52a2a">ing</span></strong> is the most fabulous part carried out by our <strong><span style="color:#1950b6">ma</span><span style="color:#83f3f2">pp</span><span style="color:#f52a2a">er</span></strong>. It takes the code below and unrolls the MaxMul loop into the Hardware.</p>

<blockquote>
  <ul>
    <li><strong>There are 2 Styles</strong>
      <ul>
        <li><strong>MAC Style(Multiply Accumulator)</strong>
          <ul>
            <li>For a 4X4 matrix a 2X2 PE array as shown will take 24 cycles give or take.</li>
            <li>For a 4X4 matrix a 4X4 PE array as shown will take 6 cycles give or take.</li>
          </ul>
        </li>
        <li><strong>SA Style (Systolic Array)</strong>
          <ul>
            <li>For a 4X4 matrix a 2X2 PE array as shown will take 24 cycles give or take.</li>
            <li>For a 4X4 matrix a 4X4 PE array as shown will take 6 cycles give or take.</li>
          </ul>
        </li>
      </ul>
    </li>
    <li>We retrofit this <strong><span style="color:#1950b6">ma</span><span style="color:#83f3f2">pp</span><span style="color:#f52a2a">er</span></strong> to trax.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/chipdesign/macstyle.png" alt="Image: figure-4: &lt;strong&gt;Hardware mapping MAC(Multiply Accumulator) Style&lt;/strong&gt;" hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-4: <strong>Hardware mapping MAC(Multiply Accumulator) Style</strong></span></center></figcaption>
</figure>

<p><a name="Optimizing on Hardware Accelerator(Systolic Array Style)"></a></p>
<h4 id="optimizing-on-hardware-acceleratorsystolic-array-style">Optimizing on Hardware Accelerator(Systolic Array Style)</h4>

<p>Same as above except the microarchitecture uses systolic array design with The PEs being pipelined. Follow the color coding especially the data movement(light and dark blue boxes and arrows) into the <strong>PEs</strong>(Processing Elements) and data forwarding among PEs. The <strong>NOC</strong>(Network On Chip) architecture which is not shown, is slightly different for both the <strong>MAC Style(Multiply Accumulator)</strong> and the <strong>SA Style (Systolic Array)</strong>.</p>

<figure>
    
    <img src="/img/chipdesign/SAStyle.png" alt="Image: figure-1: &lt;strong&gt;Hardware mapping SA(Systolic Array) Style&lt;/strong&gt;" hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-1: <strong>Hardware mapping SA(Systolic Array) Style</strong></span></center></figcaption>
</figure>

<p><a name="Variables in the design"></a></p>
<h4 id="variables-in-the-design">Variables in the design</h4>

<p>The SA Style (Systolic Array) works better for bigger tiles when it’s pipelines are fully fed for longer durations. But not too big as the NOC feeding the buffers has its own limitations. The <strong>size of the tile</strong> and indeed the <strong>style of the microarchitecture( MAC or SA)</strong> are one of the many design variables that need to be configured for best results. These in turn depend on quite a few more design variables, some of them are due to <strong>software constraints</strong> (Matrix size etc.) and others are <strong>hardware constraints</strong> (BRAM etc). Here are a few important design variables.</p>

<blockquote>
  <ul>
    <li>The <strong>SGB</strong>(size of Global Buffer) based on available BRAM and LUTRAM.
      <ul>
        <li>More LUTRAM would mean bigger buffers, better reuse, but fewer PEs and lesser parallelism.</li>
      </ul>
    </li>
    <li>The <strong>LGB</strong>(Layout(Locality) of GLobal Buffer)</li>
    <li>The size of the <strong>MT</strong> (Matrix Tile) and <strong>PET</strong>(PE Tile)</li>
    <li>The size of <strong>RF</strong>(RegisterFile)
      <ul>
        <li>As a general rule, bigger/multi-level caching(SGB/NOC/RF are like L3/L2/L1) would better lookup performance but increase data replication and eat into logic space(PEs)</li>
      </ul>
    </li>
    <li>The layout of <strong>NOC</strong>(Network on Chip)</li>
    <li><strong>With 100s of MBs to 1000 GBs of matrix sizes to choose from in modern transformers, myriad different Accelerator boards, Shape shifting configuration options on these boards, all the above variables to choose from, the configuration space is a serious problem of plenty.</strong>
      <ul>
        <li>A general configuration done by a domain expert(on Transformers and FPGA board) will give us <strong>decent improvement</strong> over a software only implementation but, <strong>nowhere near what the hardware is capable of<strong> unless the configurations are done by either Ramanujam or Tesla(Only these 2, others were normal).</strong></strong></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p><a name="Summary1"></a></p>
<h3 id="summary">Summary</h3>

<p>Migrating compute that requires extreme parallelism, or compute that can benefit from custom data path or precision should be moved to FPGA chips. Infact this is FPGA’s backyard. The overall throughput can be a few hundred times better. Latency can be a bit tricky, but still can be a lot better with the flexibility that FPGA chips offer.</p>

<h3 id="references">References</h3>
<ol>
  <li><a href="https://lwn.net/Articles/250967/"><strong>What every programmer should know about memory:</strong></a> <strong>(This is a definitive 9 part(the links for the rest of the parts are embedded in the first one.) article on how the hardware works and, how software and data structure design can exploit it. It had a huge impact on the way I thought and still do think about design. The article first came out in 2007 but it is still relevant which is proof that basics don’t change very often.)</strong></li>
</ol>

<!--Series-->

<!--Doc1-->

<!--Doc2-->

<!--External references-->

  </article>
</div>

<h3>Connect with me</h3>
Hi People, Thanks a ton for your feedback and response. If you find anything interesting or would want to connect, drop me line using the side bar.
As some of you had requested, Login has been removed from subscription form.
<div class="share-buttons">
  <h6>Share on: </h6>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/articles/2021-07/Transformers-On-Chip" class="twitter btn" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/articles/2021-07/Transformers-On-Chip" class="facebook btn" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=http://localhost:4000/articles/2021-07/Transformers-On-Chip" class="google-plus btn" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
    <li>
      <a href="https://news.ycombinator.com/submitlink?u=http://localhost:4000/articles/2021-07/Transformers-On-Chip" class="hacker-news btn" title="Share on Hacker News"><i class="fa fa-hacker-news"></i><span> Hacker News</span></a>
    </li>
    <li>
      <a href="https://www.reddit.com/submit?url=http://localhost:4000/articles/2021-07/Transformers-On-Chip" class="reddit btn" title="Share on Reddit"><i class="fa fa-reddit"></i><span> Reddit</span></a>
    </li>
  </ul>
</div><!-- end share-buttons -->
<script src="https://apis.google.com/js/plusone.js">
</script>

<script src="https://utteranc.es/client.js"
        repo="slowbreathing/slowbreathing.github.io"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>



        <footer>
  <strong>MIT License</strong> &copy; 2021 Mohit Kumar.
  <div class="newsletter-container" >
                <h4 class="newsletter-title">Subscribe</h4>
                <!-- <p class="newsletter-text"></p> -->
                <script type="text/javascript">var submitted=false;</script>
                <iframe name="hidden_iframe" id="hidden_iframe" style="display:none;"onload="if(submitted) {window.location='thankyou.html';}"></iframe>
                <form class="newsletter-form" name="gform" id="gform" enctype="text/plain" action="https://docs.google.com/forms/d/e/1FAIpQLSftY1olpvfsyxItLcV6kNsRSUQf3NQfPSL-RyT191nhPrfguA/formResponse"
                                                   target="hidden_iframe" onsubmit="submitted=true">
                    <p class="newsletter-text">Get new posts to your inbox</p>
                    <input class="newsletter-email" type="text" name="entry.1045781291" placeholder="name@example.com" />
                    <input class="newsletter-submit" type="submit" value="Subscribe" />
                </form>
  </div>
</footer>

      </div>
    </div>
  </div>
  <script type="text/javascript" src="http://localhost:4000/js/jquery-3.2.1.min.js"></script>
<script type="text/javascript" src="http://localhost:4000/js/main.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-142206738-1', 'auto');
  ga('send', 'pageview');
</script>



</body>
</html>
