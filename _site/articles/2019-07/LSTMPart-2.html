<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="description" content="In this multi-part series we look inside LSTM forward pass. Read the part-1's before you come back here. Once you are back, in this article, we explore the m...">
  <meta name="keywords" content="blog and jekyll">
  <meta name="author" content="RNN Series:LSTM internals:Part-2:The Forward pass | Slowbreathing">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#f5f5f5">

  <!-- Twitter Tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="RNN Series:LSTM internals:Part-2:The Forward pass | Slowbreathing">
  <meta name="twitter:description" content="In this multi-part series we look inside LSTM forward pass. Read the part-1&#39;s before you come back here. Once you are back, in this article, we explore the m...">
  
    <meta property="twitter:image" content="http://localhost:4000/img/leonids-logo.png">
  

  <!-- Open Graph Tags -->
  <meta property="og:type" content="blog">
  <meta property="og:url" content="http://localhost:4000/articles/2019-07/LSTMPart-2">
  <meta property="og:title" content="RNN Series:LSTM internals:Part-2:The Forward pass | Slowbreathing">
  <meta property="og:description" content="In this multi-part series we look inside LSTM forward pass. Read the part-1&#39;s before you come back here. Once you are back, in this article, we explore the m...">
  
    <meta property="og:image" content="http://localhost:4000/img/leonids-logo.png">
  
  <title>RNN Series:LSTM internals:Part-2:The Forward pass | Slowbreathing</title>

  <!-- CSS files -->
  <link rel="stylesheet" href="http://localhost:4000/css/font-awesome.min.css">
  <link rel="stylesheet" href="http://localhost:4000/css/main.css">

  <link rel="canonical" href="http://localhost:4000/articles/2019-07/LSTMPart-2">
  <link rel="alternate" type="application/rss+xml" title="Slowbreathing" href="http://localhost:4000/feed.xml" />

  <!-- Icons -->
  <!-- 16x16 -->
  <link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
  <!-- 32x32 -->
  <link rel="shortcut icon" href="http://localhost:4000/favicon.png">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!--<script async src="https://www.googletagmanager.com/gtag/js?id=UA-142206738-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-142206738-1');
  </script>-->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Slowbreathing" />
</head>


<body>
  <div class="row">
    <div class="col s12 m3">
      <div class="table cover">
        

<div class="cover-card table-cell table-middle">
  
  <a href="http://localhost:4000/">
    <img src="http://localhost:4000/img/leonids-logo.png" alt="" class="avatar">
  </a>
  
  <a href="http://localhost:4000/" class="author_name">Mohit Kumar</a>
  <span class="author_job">Researcher/Consultant/Trainer</span>
  <span class="author_bio mbm">Programming is more than just typing.</span>
  <nav class="nav">
    <ul class="nav-list">
      <li class="nav-item">
        <a href="http://localhost:4000/">home</a>
      </li>
       
      <li class="nav-item">
        <a href="http://localhost:4000/archive/">Archive</a>
      </li>
        
      <li class="nav-item">
        <a href="http://localhost:4000/categories/">Categories</a>
      </li>
            
      <li class="nav-item">
        <a href="http://localhost:4000/resume/">about me</a>
      </li>
        
      <li class="nav-item">
        <a href="http://localhost:4000/tags/">Tags</a>
      </li>
           
    </ul>
  </nav>
  <script type="text/javascript">
  // based on https://stackoverflow.com/a/10300743/280842
  function gen_mail_to_link(hs, subject) {
    var lhs,rhs;
    var p = hs.split('@');
    lhs = p[0];
    rhs = p[1];
    document.write("<a class=\"social-link-item\" target=\"_blank\" href=\"mailto");
    document.write(":" + lhs + "@");
    document.write(rhs + "?subject=" + subject + "\"><i class=\"fa fa-fw fa-envelope\"></i><\/a>");
  }
</script>
<div class="social-links">
  <ul>
    
      <li>
      <script>gen_mail_to_link('mohit.riverstone@gmail.com', 'Hello from website');</script>
      </li>
    
    <li><a href="https://twitter.com/stillwaters_ia" class="social-link-item" target="_blank"><i class="fa fa-fw fa-twitter"></i></a></li>
    <li><a href="https://facebook.com/mohit.kumar.965" class="social-link-item" target="_blank"><i class="fa fa-fw fa-facebook"></i></a></li>
    
    <li><a href="https://linkedin.com/in/mohit-kumar-36050a65" class="social-link-item" target="_blank"><i class="fa fa-fw fa-linkedin"></i></a></li>
    
    
    
    
    <li><a href="https://github.com/Slowbreathing" class="social-link-item" target="_blank"><i class="fa fa-fw fa-github"></i></a></li>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  </ul>
</div>

</div>

      </div>
    </div>
    <div class="col s12 m9">
      <div class="post-listing">
        <a class="btn" href= "http://localhost:4000/" >
  Home
</a>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://vincenttam.github.io/javascripts/MathJaxLocal.js"
>
</script>





<div id="post">
  <header class="post-header">
    <h1 title="RNN Series:LSTM internals:Part-2:The Forward pass">RNN Series:LSTM internals:Part-2:The Forward pass</h1>
    <span class="post-meta">
      <span class="post-date">
        9 JUL 2019
      </span>
      •
      <span class="read-time" title="Estimated read time">
  
  
    7 mins read
  
</span>

    </span>

  </header>

  <article class="post-content">
    <h3 id="introduction">Introduction</h3>
<p><strong>In this <a href="/tags/#LSTM">multi-part series</a> we look inside LSTM forward pass.</strong> If you havent already read it I suggest run through the previous parts (<a href="/articles/2019-07/LSTMPart-1">part-1</a>) before you come back here. Once you are back, in this article, we explore the meaning, math and the implementation of an LSTM cell. <strong>I do this using the first principles approach for which I have pure python implementation Deep-Breathe of most complex Deep Learning models.</strong></p>

<h3 id="what-this-article-is-not-about">What this article is not about?</h3>
<blockquote>
  <ul>
    <li>This article will not talk about the conceptual model of LSTM, on which there are some great existing material <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">here</a> and <a href="https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html">here</a> in thye order of difficulty.</li>
    <li>This is not about the differences between vanilla RNN and LSTMs, on which there is an awesome post by Andrej if somewhat <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">difficult post</a>.</li>
    <li>This is not about how LSTMs mitigate the vanishing gradient problem, on which there is a little mathy but awesome posts <a href="https://weberna.github.io/blog/2017/11/15/LSTM-Vanishing-Gradients.html">here</a> and <a href="https://medium.com/datadriveninvestor/how-do-lstm-networks-solve-the-problem-of-vanishing-gradients-a6784971a577">here</a> in the order of difficulty</li>
  </ul>
</blockquote>

<h3 id="what-this-article-is-about">What this article is about?</h3>
<blockquote>
  <ul>
    <li>Using the <a href="https://medium.com/the-mission/elon-musks-3-step-first-principles-thinking-how-to-think-and-solve-difficult-problems-like-a-ba1e73a9f6c0">first principles</a> we picturize the forward pass of an LSTM cell.</li>
    <li>Then we associate code with picture to make our understanding more concrete</li>
  </ul>
</blockquote>

<h3 id="context">Context</h3>
<p>This is the same example and the context is the same as described in <a href="/articles/2019-07/LSTMPart-1">part-1</a>. <strong>The focus however, this time is on LSTM cell.</strong></p>

<h3 id="lstm-cell">LSTM Cell</h3>
<p>While there are many variations to the LSTM cell. In the current article we are looking at <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LayerNormBasicLSTMCell">LayerNormBasicLSTMCell</a>.</p>
<blockquote>
  <ul>
    <li>Weights and biases of the LSTM cell.</li>
    <li>Shapes color coded.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm1.jpg" alt="Image: figure-1: Batch=1, State=5(internal states(C and H)), input_size=10(assuming vocab size of 10 translates to one-hot of size 10) ." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-1: Batch=1, State=5(internal states(C and H)), input_size=10(assuming vocab size of 10 translates to one-hot of size 10) .</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Weights, biases of the LSTM cell. Also shown is the cell state (c-state) over and above the h-state of a vanilla RNN.</li>
    <li>h<sub>t-1</sub> may be initialized by default with zeros.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm2.jpg" alt="Image: figure-2: Weights and biases for all the gates f(forget), i(input), c(candidatecellstate), o(output). Shape of these &lt;strong&gt;weights&lt;/strong&gt; are &lt;strong&gt;5X15&lt;/strong&gt; individually and stacked vertically as shown they measure &lt;strong&gt;20X15&lt;/strong&gt;. Shape of the &lt;strong&gt;biases&lt;/strong&gt; are &lt;strong&gt;5X1&lt;/strong&gt; individually and stacked up &lt;strong&gt;20X1&lt;/strong&gt;." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-2: Weights and biases for all the gates f(forget), i(input), c(candidatecellstate), o(output). Shape of these <strong>weights</strong> are <strong>5X15</strong> individually and stacked vertically as shown they measure <strong>20X15</strong>. Shape of the <strong>biases</strong> are <strong>5X1</strong> individually and stacked up <strong>20X1</strong>.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Weights and biases in the <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/org/mk/training/dl/rnn_cell.py#L76">code</a>.</li>
    <li>Often the code accepts constants as weights for comparision with <a href="https://www.tensorflow.org/">Tensorflow</a></li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm3.jpg" alt="Image: figure-3: &lt;strong&gt;4*hidden_size(5),input_size(10)+hidden_size(5)+1(biases)&lt;/strong&gt;. Making it &lt;strong&gt;20X16&lt;/strong&gt;, biases allocated with weights is a matter of convenience and performance." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-3: <strong>4*hidden_size(5),input_size(10)+hidden_size(5)+1(biases)</strong>. Making it <strong>20X16</strong>, biases allocated with weights is a matter of convenience and performance.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Equations of LSTM and their interplay with weights and biases.</li>
    <li>h<sub>t-1</sub> and c<sub>t-1</sub> may be initialized by default with zeros(Language Model) or some non-zero state for conditional language model.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm4.jpg" alt="Image: figure-4: Equations of LSTM and their interplay with weights and biases." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-4: Equations of LSTM and their interplay with weights and biases.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>GEMM(General Matrix Multiplication) in <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/org/mk/training/dl/rnn_cell.py#L210-L214">code</a></li>
    <li>h and x concatenation is only a performance convenience.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm5.jpg" alt="Image: figure-5: GEMM and running them though various gates." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-5: GEMM and running them though various gates.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>The <strong>mathematical reason</strong> why <strong>vanishing gradient</strong> is <strong>mitigated</strong>.</li>
    <li>There are many theories though. Look into this in detail with back propagation.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm6.jpg" alt="Image: figure-6: New cell state is a function of old cell state and new candidate state." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-6: New cell state is a function of old cell state and new candidate state.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>New cell state(c-state) in <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/org/mk/training/dl/rnn_cell.py#L215">code</a></li>
    <li>This is used in 2 ways as illustrated in figure-8.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm7.jpg" alt="Image: figure-7: The previous steps already decided what to do, we just need to actually do it." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-7: The previous steps already decided what to do, we just need to actually do it.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>c-state<sub>t</sub> is used to calculate the “externally visible” h-state<sub>t</sub></li>
    <li>Sometimes referred to as c<sub>t</sub>, h<sub>t</sub>, used as the states at the next time step.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm8.jpg" alt="Image: figure-8: Conceptually it is the same cell transitioning into the next state. &lt;strong&gt;In this case c&lt;sub&gt;t&lt;/sub&gt;.&lt;/strong&gt;" hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-8: Conceptually it is the same cell transitioning into the next state. <strong>In this case c<sub>t</sub>.</strong></span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>New h-state in <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/org/mk/training/dl/rnn_cell.py#L216">code</a></li>
    <li>The transition to the next time step is complete with h<sub>t</sub>.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm9.jpg" alt="Image: figure-9: Conceptually it is the same cell transitioning into the next state. &lt;strong&gt;In this case h&lt;sub&gt;t&lt;/sub&gt;.&lt;/strong&gt;" hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-9: Conceptually it is the same cell transitioning into the next state. <strong>In this case h<sub>t</sub>.</strong></span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>h<sub>t</sub> multiplied by the <strong>“Wy”</strong> and <strong>“by”</strong> added to it.</li>
    <li>Traditionally we call this value “logits” or “preds”.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm10.jpg" alt="Image: figure-10: Wy shape is 10X5 multiplied by h&lt;sub&gt;t&lt;/sub&gt; which is 5X1 and by added to it which is 10X1 as shown above." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-10: Wy shape is 10X5 multiplied by h<sub>t</sub> which is 5X1 and by added to it which is 10X1 as shown above.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Usually this is done in on the client side code because only the clients know the model and when the loss calculation can be done.</li>
    <li>Tensorflow version of the <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/org/mk/training/dl/tfwordslstm.py#L95-L104">code</a>.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm11.jpg" alt="Image: figure-11: DEEP-Breathe version of the &lt;a href='https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/org/mk/training/dl/LSTMMainGraph.py#L98-L109'&gt;code&lt;/a&gt;." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-11: DEEP-Breathe version of the <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/org/mk/training/dl/LSTMMainGraph.py#L98-L109">code</a>.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Usually done internally by “cross_entropy_loss” function.</li>
    <li>Shown here just so that you get an idea.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm12.jpg" alt="Image: figure-12: Traditionally called yhat." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-12: Traditionally called yhat.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Does a combination of softmax(figure-12) and loss calculation(figure-13).</li>
    <li><a href="/articles/2019-05/softmax-and-its-gradient">Softmax</a> and a <a href="/articles/2019-05/softmax-and-cross-entropy">cross_entropy_loss</a> to jog your memory.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm13.jpg" alt="Image: figure-13: Similar to logistic regression and its cost function." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-13: Similar to logistic regression and its cost function.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li><strong>Summary with weights</strong>.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstmcelltemplate5.jpg" alt="Image: figure-15: &lt;strong&gt;Summary with weights.&lt;/strong&gt;" hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-15: <strong>Summary with weights.</strong></span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li><strong>Summary as flow diagram</strong>.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstmforward.jpg" alt="Image: figure-14: &lt;strong&gt;Summary as simple flow diagram.&lt;/strong&gt;" hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-14: <strong>Summary as simple flow diagram.</strong></span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Sequence of 3 shown below, but that can depend on the use-case.</li>
    <li>Tensorflow version of the <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/org/mk/training/dl/tfwordslstm.py#L95-L104">code</a> and DEEP-Breathe version of the <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/org/mk/training/dl/LSTMMainGraph.py#L98-L109">code</a>.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm14.jpg" alt="Image: figure-16: The code below is merely shown to give you an idea of the sequence. In practice the 'dynamic_rnn' function does iteration part, the preds are multiplied 'Wy' added to 'By' by client code and then handed over to 'cross_entropy_loss' function." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-16: The code below is merely shown to give you an idea of the sequence. In practice the 'dynamic_rnn' function does iteration part, the preds are multiplied 'Wy' added to 'By' by client code and then handed over to 'cross_entropy_loss' function.</span></center></figcaption>
</figure>

<h3 id="summary">Summary</h3>
<p>In summary then, that was the walk though of LSTM’s forward pass. As a study in contrast, if building a Language model that predicts the next word in the sequence, the training would be similar but we’ll calculate loss at every step. The label would be the ‘X’ just one time step advanced. However, Lets not get ahead of ourselves, before we get to a language model, lets look at the backward pass(Back Propagation) for LSTM in the next post.</p>


  </article>
</div>

<div class="share-buttons">
  <h6>Share on: </h6>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/articles/2019-07/LSTMPart-2" class="twitter btn" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/articles/2019-07/LSTMPart-2" class="facebook btn" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=http://localhost:4000/articles/2019-07/LSTMPart-2" class="google-plus btn" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
    <li>
      <a href="https://news.ycombinator.com/submitlink?u=http://localhost:4000/articles/2019-07/LSTMPart-2" class="hacker-news btn" title="Share on Hacker News"><i class="fa fa-hacker-news"></i><span> Hacker News</span></a>
    </li>
    <li>
      <a href="https://www.reddit.com/submit?url=http://localhost:4000/articles/2019-07/LSTMPart-2" class="reddit btn" title="Share on Reddit"><i class="fa fa-reddit"></i><span> Reddit</span></a>
    </li>
  </ul>
</div><!-- end share-buttons -->
<script src="https://apis.google.com/js/plusone.js">
</script>



        <footer>
  <strong>MIT License</strong> &copy; 2019 Mohit Kumar.
  <form style="border:1px solid #ccc;padding:3px;text-align:center;" action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open('https://feedburner.google.com/fb/a/mailverify?uri=Slowbreathing', 'popupwindow', 'scrollbars=yes,width=550,height=520');return true"><p>Enter your email address:</p><p><input type="text" style="width:140px" name="email"/></p><input type="hidden" value="Slowbreathing" name="uri"/><input type="hidden" name="loc" value="en_US"/><input type="submit" value="Subscribe" /><p>Delivered by <a href="https://feedburner.google.com" target="_blank">FeedBurner</a></p></form>
</footer>

      </div>
    </div>
  </div>
  <script type="text/javascript" src="http://localhost:4000/js/jquery-3.2.1.min.js"></script>
<script type="text/javascript" src="http://localhost:4000/js/main.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-142206738-1', 'auto');
  ga('send', 'pageview');
</script>



</body>
</html>
